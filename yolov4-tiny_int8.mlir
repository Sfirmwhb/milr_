module  {
  func @tpu_func(%arg0: tensor<1x3x416x416xf32>) -> (tensor<1x2535x1x4xf32>, tensor<1x2535x80xf32>) attributes {chipname = "cv183x"} {
    %0 = "tpu.weight_file"() {filename = "yolov4-tiny_5_39426fd72048.npz"} : () -> memref<10xf32>
    %1 = "tpu.input"(%arg0) {name = "input", preprocess = {color_order = "bgr", data_format = "nchw", input_scale = 1.000000e+00 : f32, mean = [0.000000e+00 : f32, 0.000000e+00 : f32, 0.000000e+00 : f32], raw_scale = 2.550000e+02 : f32, std = [1.000000e+00 : f32, 1.000000e+00 : f32, 1.000000e+00 : f32]}, quant = {is_asymmetric = false, is_perchannel = false, mode = "NONE", param_type = "THRESHOLD", threshold_max = 2.641290e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x416x416xf32>) -> tensor<1x3x416x416xf32>
    %2 = "tpu.none"() : () -> none
    %3 = "tpu.load_weight"(%0) {name = "120_BatchNormalization_merge_scale_0_51.264450_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<32x3x3x3xf32>
    %4 = "tpu.load_weight"(%0) {name = "120_BatchNormalization_merge_scale_1_51.264450_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<32xf32>
    %5 = "tpu.load_weight"(%0) {name = "120_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %6 = "tpu.load_weight"(%0) {name = "120_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %7 = "tpu.quant"(%1) {from = "NONE", name = "input_quant", threshold = 2.641290e+00 : f32, to = "INT8", zero_point = 0 : i32} : (tensor<1x3x416x416xf32>) -> tensor<1x3x416x416xi8>
    %8 = "tpu.conv_2d"(%7, %3, %4, %2, %2, %5, %6) {name = "120_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 2 : i32, stride_w = 2 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 51.2644501 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x416x416xi8>, tensor<32x3x3x3xf32>, tensor<32xf32>, none, none, tensor<32xf32>, tensor<32xf32>) -> tensor<1x32x208x208xsi8>
    %9 = "tpu.none"() : () -> none
    %10 = "tpu.load_weight"(%0) {name = "121_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %11 = "tpu.load_weight"(%0) {name = "121_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %12 = "tpu.load_weight"(%0) {name = "121_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %13 = "tpu.load_weight"(%0) {name = "121_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %14 = "tpu.leaky_relu"(%8, %9, %9, %9, %9, %10, %11, %12, %13) {name = "121_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 51.2644501 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x208x208xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x32x208x208xsi8>
    %15 = "tpu.none"() : () -> none
    %16 = "tpu.load_weight"(%0) {name = "123_BatchNormalization_merge_scale_0_69.456528_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<64x32x3x3xf32>
    %17 = "tpu.load_weight"(%0) {name = "123_BatchNormalization_merge_scale_1_69.456528_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<64xf32>
    %18 = "tpu.load_weight"(%0) {name = "123_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %19 = "tpu.load_weight"(%0) {name = "123_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %20 = "tpu.conv_2d"(%14, %16, %17, %15, %15, %18, %19) {name = "123_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 2 : i32, stride_w = 2 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 69.4565277 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x208x208xsi8>, tensor<64x32x3x3xf32>, tensor<64xf32>, none, none, tensor<64xf32>, tensor<64xf32>) -> tensor<1x64x104x104xsi8>
    %21 = "tpu.none"() : () -> none
    %22 = "tpu.load_weight"(%0) {name = "124_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %23 = "tpu.load_weight"(%0) {name = "124_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %24 = "tpu.load_weight"(%0) {name = "124_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %25 = "tpu.load_weight"(%0) {name = "124_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %26 = "tpu.leaky_relu"(%20, %21, %21, %21, %21, %22, %23, %24, %25) {name = "124_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 69.4565277 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x64x104x104xsi8>
    %27 = "tpu.none"() : () -> none
    %28 = "tpu.load_weight"(%0) {name = "126_BatchNormalization_merge_scale_0_39.166340_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<64x64x3x3xf32>
    %29 = "tpu.load_weight"(%0) {name = "126_BatchNormalization_merge_scale_1_39.166340_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<64xf32>
    %30 = "tpu.load_weight"(%0) {name = "126_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %31 = "tpu.load_weight"(%0) {name = "126_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %32 = "tpu.conv_2d"(%26, %28, %29, %27, %27, %30, %31) {name = "126_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 39.1663399 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, tensor<64x64x3x3xf32>, tensor<64xf32>, none, none, tensor<64xf32>, tensor<64xf32>) -> tensor<1x64x104x104xsi8>
    %33 = "tpu.none"() : () -> none
    %34 = "tpu.load_weight"(%0) {name = "127_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %35 = "tpu.load_weight"(%0) {name = "127_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %36 = "tpu.load_weight"(%0) {name = "127_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %37 = "tpu.load_weight"(%0) {name = "127_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %38 = "tpu.leaky_relu"(%32, %33, %33, %33, %33, %34, %35, %36, %37) {name = "127_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 39.1663399 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x64x104x104xsi8>
    %39 = "tpu.crop"(%38) {crop_offset = [0 : i32, 32 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 32 : i32, 104 : i32, 104 : i32], name = "146_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 39.1663399 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>) -> tensor<1x32x104x104xsi8>
    %40 = "tpu.none"() : () -> none
    %41 = "tpu.load_weight"(%0) {name = "148_BatchNormalization_merge_scale_0_51.325260_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<32x32x3x3xf32>
    %42 = "tpu.load_weight"(%0) {name = "148_BatchNormalization_merge_scale_1_51.325260_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<32xf32>
    %43 = "tpu.load_weight"(%0) {name = "148_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %44 = "tpu.load_weight"(%0) {name = "148_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %45 = "tpu.conv_2d"(%39, %41, %42, %40, %40, %43, %44) {name = "148_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 51.3252602 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x104x104xsi8>, tensor<32x32x3x3xf32>, tensor<32xf32>, none, none, tensor<32xf32>, tensor<32xf32>) -> tensor<1x32x104x104xsi8>
    %46 = "tpu.none"() : () -> none
    %47 = "tpu.load_weight"(%0) {name = "149_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %48 = "tpu.load_weight"(%0) {name = "149_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %49 = "tpu.load_weight"(%0) {name = "149_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %50 = "tpu.load_weight"(%0) {name = "149_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %51 = "tpu.leaky_relu"(%45, %46, %46, %46, %46, %47, %48, %49, %50) {name = "149_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 51.3252602 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x104x104xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x32x104x104xsi8>
    %52 = "tpu.none"() : () -> none
    %53 = "tpu.load_weight"(%0) {name = "151_BatchNormalization_merge_scale_0_49.287769_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<32x32x3x3xf32>
    %54 = "tpu.load_weight"(%0) {name = "151_BatchNormalization_merge_scale_1_49.287769_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<32xf32>
    %55 = "tpu.load_weight"(%0) {name = "151_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %56 = "tpu.load_weight"(%0) {name = "151_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<32xf32>
    %57 = "tpu.conv_2d"(%51, %53, %54, %52, %52, %55, %56) {name = "151_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 49.2877693 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x104x104xsi8>, tensor<32x32x3x3xf32>, tensor<32xf32>, none, none, tensor<32xf32>, tensor<32xf32>) -> tensor<1x32x104x104xsi8>
    %58 = "tpu.none"() : () -> none
    %59 = "tpu.load_weight"(%0) {name = "152_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %60 = "tpu.load_weight"(%0) {name = "152_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %61 = "tpu.load_weight"(%0) {name = "152_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %62 = "tpu.load_weight"(%0) {name = "152_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %63 = "tpu.leaky_relu"(%57, %58, %58, %58, %58, %59, %60, %61, %62) {name = "152_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 49.2877693 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x104x104xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x32x104x104xsi8>
    %64 = "tpu.none"() : () -> none
    %65 = "tpu.load_weight"(%0) {name = "153_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %66 = "tpu.load_weight"(%0) {name = "153_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %67 = "tpu.concat"(%63, %51, %64, %64, %65, %66) {axis = 1 : i32, name = "153_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 51.3252602 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x32x104x104xsi8>, tensor<1x32x104x104xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x64x104x104xsi8>
    %68 = "tpu.none"() : () -> none
    %69 = "tpu.load_weight"(%0) {name = "155_BatchNormalization_merge_scale_0_23.835270_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<64x64x1x1xf32>
    %70 = "tpu.load_weight"(%0) {name = "155_BatchNormalization_merge_scale_1_23.835270_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<64xf32>
    %71 = "tpu.load_weight"(%0) {name = "155_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %72 = "tpu.load_weight"(%0) {name = "155_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %73 = "tpu.conv_2d"(%67, %69, %70, %68, %68, %71, %72) {name = "155_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 23.8352699 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, tensor<64x64x1x1xf32>, tensor<64xf32>, none, none, tensor<64xf32>, tensor<64xf32>) -> tensor<1x64x104x104xsi8>
    %74 = "tpu.none"() : () -> none
    %75 = "tpu.load_weight"(%0) {name = "156_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %76 = "tpu.load_weight"(%0) {name = "156_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %77 = "tpu.load_weight"(%0) {name = "156_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %78 = "tpu.load_weight"(%0) {name = "156_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %79 = "tpu.leaky_relu"(%73, %74, %74, %74, %74, %75, %76, %77, %78) {name = "156_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 23.8352699 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x64x104x104xsi8>
    %80 = "tpu.none"() : () -> none
    %81 = "tpu.load_weight"(%0) {name = "157_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %82 = "tpu.load_weight"(%0) {name = "157_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %83 = "tpu.concat"(%38, %79, %80, %80, %81, %82) {axis = 1 : i32, name = "157_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 78.3326797 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x104x104xsi8>, tensor<1x64x104x104xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x128x104x104xsi8>
    %84 = "tpu.pool_max_2d"(%83) {name = "158_MaxPool", param = {count_include_pad = false, do_relu = false, kernel_h = 2 : i32, kernel_w = 2 : i32, pad_value = 0 : i32, padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 2 : i32, stride_w = 2 : i32}, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 78.3326797 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x104x104xsi8>) -> tensor<1x128x52x52xsi8>
    %85 = "tpu.none"() : () -> none
    %86 = "tpu.load_weight"(%0) {name = "160_BatchNormalization_merge_scale_0_20.640499_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<128x128x3x3xf32>
    %87 = "tpu.load_weight"(%0) {name = "160_BatchNormalization_merge_scale_1_20.640499_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<128xf32>
    %88 = "tpu.load_weight"(%0) {name = "160_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %89 = "tpu.load_weight"(%0) {name = "160_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %90 = "tpu.conv_2d"(%84, %86, %87, %85, %85, %88, %89) {name = "160_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 2.064050e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>, tensor<128x128x3x3xf32>, tensor<128xf32>, none, none, tensor<128xf32>, tensor<128xf32>) -> tensor<1x128x52x52xsi8>
    %91 = "tpu.none"() : () -> none
    %92 = "tpu.load_weight"(%0) {name = "161_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %93 = "tpu.load_weight"(%0) {name = "161_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %94 = "tpu.load_weight"(%0) {name = "161_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %95 = "tpu.load_weight"(%0) {name = "161_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %96 = "tpu.leaky_relu"(%90, %91, %91, %91, %91, %92, %93, %94, %95) {name = "161_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 2.064050e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x128x52x52xsi8>
    %97 = "tpu.crop"(%96) {crop_offset = [0 : i32, 64 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 64 : i32, 52 : i32, 52 : i32], name = "180_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.064050e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>) -> tensor<1x64x52x52xsi8>
    %98 = "tpu.none"() : () -> none
    %99 = "tpu.load_weight"(%0) {name = "182_BatchNormalization_merge_scale_0_21.632450_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<64x64x3x3xf32>
    %100 = "tpu.load_weight"(%0) {name = "182_BatchNormalization_merge_scale_1_21.632450_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<64xf32>
    %101 = "tpu.load_weight"(%0) {name = "182_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %102 = "tpu.load_weight"(%0) {name = "182_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %103 = "tpu.conv_2d"(%97, %99, %100, %98, %98, %101, %102) {name = "182_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 21.6324501 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x52x52xsi8>, tensor<64x64x3x3xf32>, tensor<64xf32>, none, none, tensor<64xf32>, tensor<64xf32>) -> tensor<1x64x52x52xsi8>
    %104 = "tpu.none"() : () -> none
    %105 = "tpu.load_weight"(%0) {name = "183_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %106 = "tpu.load_weight"(%0) {name = "183_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %107 = "tpu.load_weight"(%0) {name = "183_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %108 = "tpu.load_weight"(%0) {name = "183_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %109 = "tpu.leaky_relu"(%103, %104, %104, %104, %104, %105, %106, %107, %108) {name = "183_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 21.6324501 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x52x52xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x64x52x52xsi8>
    %110 = "tpu.none"() : () -> none
    %111 = "tpu.load_weight"(%0) {name = "185_BatchNormalization_merge_scale_0_29.885639_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<64x64x3x3xf32>
    %112 = "tpu.load_weight"(%0) {name = "185_BatchNormalization_merge_scale_1_29.885639_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<64xf32>
    %113 = "tpu.load_weight"(%0) {name = "185_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %114 = "tpu.load_weight"(%0) {name = "185_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<64xf32>
    %115 = "tpu.conv_2d"(%109, %111, %112, %110, %110, %113, %114) {name = "185_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 29.8856392 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x52x52xsi8>, tensor<64x64x3x3xf32>, tensor<64xf32>, none, none, tensor<64xf32>, tensor<64xf32>) -> tensor<1x64x52x52xsi8>
    %116 = "tpu.none"() : () -> none
    %117 = "tpu.load_weight"(%0) {name = "186_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %118 = "tpu.load_weight"(%0) {name = "186_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %119 = "tpu.load_weight"(%0) {name = "186_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %120 = "tpu.load_weight"(%0) {name = "186_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %121 = "tpu.leaky_relu"(%115, %116, %116, %116, %116, %117, %118, %119, %120) {name = "186_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 29.8856392 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x52x52xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x64x52x52xsi8>
    %122 = "tpu.none"() : () -> none
    %123 = "tpu.load_weight"(%0) {name = "187_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %124 = "tpu.load_weight"(%0) {name = "187_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %125 = "tpu.concat"(%121, %109, %122, %122, %123, %124) {axis = 1 : i32, name = "187_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 2.490470e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x64x52x52xsi8>, tensor<1x64x52x52xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x128x52x52xsi8>
    %126 = "tpu.none"() : () -> none
    %127 = "tpu.load_weight"(%0) {name = "189_BatchNormalization_merge_scale_0_19.022249_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<128x128x1x1xf32>
    %128 = "tpu.load_weight"(%0) {name = "189_BatchNormalization_merge_scale_1_19.022249_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<128xf32>
    %129 = "tpu.load_weight"(%0) {name = "189_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %130 = "tpu.load_weight"(%0) {name = "189_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %131 = "tpu.conv_2d"(%125, %127, %128, %126, %126, %129, %130) {name = "189_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 19.0222492 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>, tensor<128x128x1x1xf32>, tensor<128xf32>, none, none, tensor<128xf32>, tensor<128xf32>) -> tensor<1x128x52x52xsi8>
    %132 = "tpu.none"() : () -> none
    %133 = "tpu.load_weight"(%0) {name = "190_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %134 = "tpu.load_weight"(%0) {name = "190_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %135 = "tpu.load_weight"(%0) {name = "190_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %136 = "tpu.load_weight"(%0) {name = "190_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %137 = "tpu.leaky_relu"(%131, %132, %132, %132, %132, %133, %134, %135, %136) {name = "190_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 19.0222492 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x128x52x52xsi8>
    %138 = "tpu.none"() : () -> none
    %139 = "tpu.load_weight"(%0) {name = "191_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %140 = "tpu.load_weight"(%0) {name = "191_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %141 = "tpu.concat"(%96, %137, %138, %138, %139, %140) {axis = 1 : i32, name = "191_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 61.6840401 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x52x52xsi8>, tensor<1x128x52x52xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x256x52x52xsi8>
    %142 = "tpu.pool_max_2d"(%141) {name = "192_MaxPool", param = {count_include_pad = false, do_relu = false, kernel_h = 2 : i32, kernel_w = 2 : i32, pad_value = 0 : i32, padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 2 : i32, stride_w = 2 : i32}, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 61.6840401 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x52x52xsi8>) -> tensor<1x256x26x26xsi8>
    %143 = "tpu.none"() : () -> none
    %144 = "tpu.load_weight"(%0) {name = "194_BatchNormalization_merge_scale_0_13.216900_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<256x256x3x3xf32>
    %145 = "tpu.load_weight"(%0) {name = "194_BatchNormalization_merge_scale_1_13.216900_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<256xf32>
    %146 = "tpu.load_weight"(%0) {name = "194_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %147 = "tpu.load_weight"(%0) {name = "194_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %148 = "tpu.conv_2d"(%142, %144, %145, %143, %143, %146, %147) {name = "194_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 1.321690e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, tensor<256x256x3x3xf32>, tensor<256xf32>, none, none, tensor<256xf32>, tensor<256xf32>) -> tensor<1x256x26x26xsi8>
    %149 = "tpu.none"() : () -> none
    %150 = "tpu.load_weight"(%0) {name = "195_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %151 = "tpu.load_weight"(%0) {name = "195_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %152 = "tpu.load_weight"(%0) {name = "195_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %153 = "tpu.load_weight"(%0) {name = "195_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %154 = "tpu.leaky_relu"(%148, %149, %149, %149, %149, %150, %151, %152, %153) {name = "195_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.321690e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x256x26x26xsi8>
    %155 = "tpu.crop"(%154) {crop_offset = [0 : i32, 128 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 128 : i32, 26 : i32, 26 : i32], name = "214_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.321690e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>) -> tensor<1x128x26x26xsi8>
    %156 = "tpu.none"() : () -> none
    %157 = "tpu.load_weight"(%0) {name = "216_BatchNormalization_merge_scale_0_17.478769_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<128x128x3x3xf32>
    %158 = "tpu.load_weight"(%0) {name = "216_BatchNormalization_merge_scale_1_17.478769_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<128xf32>
    %159 = "tpu.load_weight"(%0) {name = "216_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %160 = "tpu.load_weight"(%0) {name = "216_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %161 = "tpu.conv_2d"(%155, %157, %158, %156, %156, %159, %160) {name = "216_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 17.4787693 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, tensor<128x128x3x3xf32>, tensor<128xf32>, none, none, tensor<128xf32>, tensor<128xf32>) -> tensor<1x128x26x26xsi8>
    %162 = "tpu.none"() : () -> none
    %163 = "tpu.load_weight"(%0) {name = "217_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %164 = "tpu.load_weight"(%0) {name = "217_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %165 = "tpu.load_weight"(%0) {name = "217_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %166 = "tpu.load_weight"(%0) {name = "217_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %167 = "tpu.leaky_relu"(%161, %162, %162, %162, %162, %163, %164, %165, %166) {name = "217_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 17.4787693 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x128x26x26xsi8>
    %168 = "tpu.none"() : () -> none
    %169 = "tpu.load_weight"(%0) {name = "219_BatchNormalization_merge_scale_0_19.259010_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<128x128x3x3xf32>
    %170 = "tpu.load_weight"(%0) {name = "219_BatchNormalization_merge_scale_1_19.259010_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<128xf32>
    %171 = "tpu.load_weight"(%0) {name = "219_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %172 = "tpu.load_weight"(%0) {name = "219_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %173 = "tpu.conv_2d"(%167, %169, %170, %168, %168, %171, %172) {name = "219_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 19.2590103 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, tensor<128x128x3x3xf32>, tensor<128xf32>, none, none, tensor<128xf32>, tensor<128xf32>) -> tensor<1x128x26x26xsi8>
    %174 = "tpu.none"() : () -> none
    %175 = "tpu.load_weight"(%0) {name = "220_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %176 = "tpu.load_weight"(%0) {name = "220_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %177 = "tpu.load_weight"(%0) {name = "220_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %178 = "tpu.load_weight"(%0) {name = "220_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %179 = "tpu.leaky_relu"(%173, %174, %174, %174, %174, %175, %176, %177, %178) {name = "220_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 19.2590103 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x128x26x26xsi8>
    %180 = "tpu.none"() : () -> none
    %181 = "tpu.load_weight"(%0) {name = "221_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %182 = "tpu.load_weight"(%0) {name = "221_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %183 = "tpu.concat"(%179, %167, %180, %180, %181, %182) {axis = 1 : i32, name = "221_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 15.4072104 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, tensor<1x128x26x26xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x256x26x26xsi8>
    %184 = "tpu.none"() : () -> none
    %185 = "tpu.load_weight"(%0) {name = "223_BatchNormalization_merge_scale_0_11.466220_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<256x256x1x1xf32>
    %186 = "tpu.load_weight"(%0) {name = "223_BatchNormalization_merge_scale_1_11.466220_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<256xf32>
    %187 = "tpu.load_weight"(%0) {name = "223_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %188 = "tpu.load_weight"(%0) {name = "223_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %189 = "tpu.conv_2d"(%183, %185, %186, %184, %184, %187, %188) {name = "223_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 11.4662199 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, tensor<256x256x1x1xf32>, tensor<256xf32>, none, none, tensor<256xf32>, tensor<256xf32>) -> tensor<1x256x26x26xsi8>
    %190 = "tpu.none"() : () -> none
    %191 = "tpu.load_weight"(%0) {name = "224_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %192 = "tpu.load_weight"(%0) {name = "224_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %193 = "tpu.load_weight"(%0) {name = "224_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %194 = "tpu.load_weight"(%0) {name = "224_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %195 = "tpu.leaky_relu"(%189, %190, %190, %190, %190, %191, %192, %193, %194) {name = "224_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 11.4662199 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x256x26x26xsi8>
    %196 = "tpu.none"() : () -> none
    %197 = "tpu.load_weight"(%0) {name = "225_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %198 = "tpu.load_weight"(%0) {name = "225_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %199 = "tpu.concat"(%154, %195, %196, %196, %197, %198) {axis = 1 : i32, name = "225_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 29.5367508 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, tensor<1x256x26x26xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x512x26x26xsi8>
    %200 = "tpu.pool_max_2d"(%199) {name = "226_MaxPool", param = {count_include_pad = false, do_relu = false, kernel_h = 2 : i32, kernel_w = 2 : i32, pad_value = 0 : i32, padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 2 : i32, stride_w = 2 : i32}, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 29.5367508 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x26x26xsi8>) -> tensor<1x512x13x13xsi8>
    %201 = "tpu.none"() : () -> none
    %202 = "tpu.load_weight"(%0) {name = "228_BatchNormalization_merge_scale_0_16.132780_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<512x512x3x3xf32>
    %203 = "tpu.load_weight"(%0) {name = "228_BatchNormalization_merge_scale_1_16.132780_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<512xf32>
    %204 = "tpu.load_weight"(%0) {name = "228_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<512xf32>
    %205 = "tpu.load_weight"(%0) {name = "228_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<512xf32>
    %206 = "tpu.conv_2d"(%200, %202, %203, %201, %201, %204, %205) {name = "228_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 16.1327801 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x13x13xsi8>, tensor<512x512x3x3xf32>, tensor<512xf32>, none, none, tensor<512xf32>, tensor<512xf32>) -> tensor<1x512x13x13xsi8>
    %207 = "tpu.none"() : () -> none
    %208 = "tpu.load_weight"(%0) {name = "229_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %209 = "tpu.load_weight"(%0) {name = "229_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %210 = "tpu.load_weight"(%0) {name = "229_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %211 = "tpu.load_weight"(%0) {name = "229_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %212 = "tpu.leaky_relu"(%206, %207, %207, %207, %207, %208, %209, %210, %211) {name = "229_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 16.1327801 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x13x13xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x512x13x13xsi8>
    %213 = "tpu.none"() : () -> none
    %214 = "tpu.load_weight"(%0) {name = "231_BatchNormalization_merge_scale_0_20.339689_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<256x512x1x1xf32>
    %215 = "tpu.load_weight"(%0) {name = "231_BatchNormalization_merge_scale_1_20.339689_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<256xf32>
    %216 = "tpu.load_weight"(%0) {name = "231_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %217 = "tpu.load_weight"(%0) {name = "231_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %218 = "tpu.conv_2d"(%212, %214, %215, %213, %213, %216, %217) {name = "231_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 20.3396893 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x13x13xsi8>, tensor<256x512x1x1xf32>, tensor<256xf32>, none, none, tensor<256xf32>, tensor<256xf32>) -> tensor<1x256x13x13xsi8>
    %219 = "tpu.none"() : () -> none
    %220 = "tpu.load_weight"(%0) {name = "232_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %221 = "tpu.load_weight"(%0) {name = "232_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %222 = "tpu.load_weight"(%0) {name = "232_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %223 = "tpu.load_weight"(%0) {name = "232_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %224 = "tpu.leaky_relu"(%218, %219, %219, %219, %219, %220, %221, %222, %223) {name = "232_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 20.3396893 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x13x13xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x256x13x13xsi8>
    %225 = "tpu.none"() : () -> none
    %226 = "tpu.load_weight"(%0) {name = "234_BatchNormalization_merge_scale_0_28.319771_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<512x256x3x3xf32>
    %227 = "tpu.load_weight"(%0) {name = "234_BatchNormalization_merge_scale_1_28.319771_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<512xf32>
    %228 = "tpu.load_weight"(%0) {name = "234_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<512xf32>
    %229 = "tpu.load_weight"(%0) {name = "234_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<512xf32>
    %230 = "tpu.conv_2d"(%224, %226, %227, %225, %225, %228, %229) {name = "234_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 28.3197708 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x13x13xsi8>, tensor<512x256x3x3xf32>, tensor<512xf32>, none, none, tensor<512xf32>, tensor<512xf32>) -> tensor<1x512x13x13xsi8>
    %231 = "tpu.none"() : () -> none
    %232 = "tpu.load_weight"(%0) {name = "235_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %233 = "tpu.load_weight"(%0) {name = "235_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %234 = "tpu.load_weight"(%0) {name = "235_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %235 = "tpu.load_weight"(%0) {name = "235_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %236 = "tpu.leaky_relu"(%230, %231, %231, %231, %231, %232, %233, %234, %235) {name = "235_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 28.3197708 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x13x13xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x512x13x13xsi8>
    %237 = "tpu.load_weight"(%0) {name = "models.29.conv18.weight_4.196190_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<255x512x1x1xf32>
    %238 = "tpu.load_weight"(%0) {name = "models.29.conv18.bias_4.196190_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<255xf32>
    %239 = "tpu.none"() : () -> none
    %240 = "tpu.load_weight"(%0) {name = "236_Conv_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<255xf32>
    %241 = "tpu.load_weight"(%0) {name = "236_Conv_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<255xf32>
    %242 = "tpu.conv_2d"(%236, %237, %238, %239, %239, %240, %241) {name = "236_Conv", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 4.196190e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x512x13x13xsi8>, tensor<255x512x1x1xf32>, tensor<255xf32>, none, none, tensor<255xf32>, tensor<255xf32>) -> tensor<1x255x13x13xsi8>
    %243 = "tpu.crop"(%242) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "241_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 4.196190e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %244 = "tpu.crop"(%242) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "246_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.673770e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %245 = "tpu.crop"(%242) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "251_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 23.1181107 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %246 = "tpu.crop"(%242) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 13 : i32, 13 : i32], name = "256_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 65.8174133 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x80x13x13xsi8>
    %247 = "tpu.crop"(%242) {crop_offset = [0 : i32, 85 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "261_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 4.816490e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %248 = "tpu.crop"(%242) {crop_offset = [0 : i32, 87 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "266_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.938370e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %249 = "tpu.crop"(%242) {crop_offset = [0 : i32, 89 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "271_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 19.7889194 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %250 = "tpu.crop"(%242) {crop_offset = [0 : i32, 90 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 13 : i32, 13 : i32], name = "276_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 71.1903915 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x80x13x13xsi8>
    %251 = "tpu.crop"(%242) {crop_offset = [0 : i32, 170 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "281_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 4.231080e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %252 = "tpu.crop"(%242) {crop_offset = [0 : i32, 172 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 13 : i32, 13 : i32], name = "286_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.795710e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x2x13x13xsi8>
    %253 = "tpu.crop"(%242) {crop_offset = [0 : i32, 174 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "291_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.346520e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %254 = "tpu.crop"(%242) {crop_offset = [0 : i32, 175 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 13 : i32, 13 : i32], name = "296_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 56.0192604 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x13x13xsi8>) -> tensor<1x80x13x13xsi8>
    %255 = "tpu.none"() : () -> none
    %256 = "tpu.load_weight"(%0) {name = "297_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %257 = "tpu.load_weight"(%0) {name = "297_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %258 = "tpu.concat"(%243, %247, %251, %255, %255, %256, %257) {axis = 1 : i32, name = "297_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 4.816490e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2x13x13xsi8>, tensor<1x2x13x13xsi8>, tensor<1x2x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x6x13x13xsi8>
    %259 = "tpu.none"() : () -> none
    %260 = "tpu.load_weight"(%0) {name = "298_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %261 = "tpu.load_weight"(%0) {name = "298_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %262 = "tpu.concat"(%244, %248, %252, %259, %259, %260, %261) {axis = 1 : i32, name = "298_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.938370e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2x13x13xsi8>, tensor<1x2x13x13xsi8>, tensor<1x2x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x6x13x13xsi8>
    %263 = "tpu.none"() : () -> none
    %264 = "tpu.load_weight"(%0) {name = "299_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %265 = "tpu.load_weight"(%0) {name = "299_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %266 = "tpu.concat"(%245, %249, %253, %263, %263, %264, %265) {axis = 1 : i32, name = "299_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 2.346520e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x13x13xsi8>
    %267 = "tpu.reshape"(%266) {name = "315_Reshape"} : (tensor<1x3x13x13xsi8>) -> tensor<1x507xsi8>
    %268 = "tpu.none"() : () -> none
    %269 = "tpu.load_weight"(%0) {name = "316_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %270 = "tpu.load_weight"(%0) {name = "316_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %271 = "tpu.concat"(%246, %250, %254, %268, %268, %269, %270) {axis = 1 : i32, name = "316_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 71.1903915 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x80x13x13xsi8>, tensor<1x80x13x13xsi8>, tensor<1x80x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x240x13x13xsi8>
    %272 = "tpu.reshape"(%271) {name = "334_Reshape"} : (tensor<1x240x13x13xsi8>) -> tensor<1x3x80x169xsi8>
    %273 = "tpu.reshape"(%272) {name = "335_Transpose_for_0231"} : (tensor<1x3x80x169xsi8>) -> tensor<3x80x1x169xsi8>
    %274 = "tpu.permute"(%273) {name = "335_Transpose", order0 = 0 : i32, order1 = 2 : i32, order2 = 3 : i32, order3 = 1 : i32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 71.1903915 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<3x80x1x169xsi8>) -> tensor<3x1x169x80xsi8>
    %275 = "tpu.reshape"(%274) {name = "335_Transpose_back_for_0231"} : (tensor<3x1x169x80xsi8>) -> tensor<1x3x169x80xsi8>
    %276 = "tpu.reshape"(%275) {name = "353_Reshape"} : (tensor<1x3x169x80xsi8>) -> tensor<1x507x80xsi8>
    %277 = "tpu.load_weight"(%0) {name = "354_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %278 = "tpu.load_weight"(%0) {name = "354_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %279 = "tpu.sigmoid"(%258, %277, %278) {name = "354_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 0.992439985 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x6x13x13xsi8>
    %280 = "tpu.load_weight"(%0) {name = "358_Sub_fold_0_scale_1.009890_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %281 = "tpu.load_weight"(%0) {name = "358_Sub_fold_1_scale_1.009890_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %282 = "tpu.none"() : () -> none
    %283 = "tpu.load_weight"(%0) {name = "358_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %284 = "tpu.load_weight"(%0) {name = "358_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %285 = "tpu.conv_2d"(%279, %280, %281, %282, %282, %283, %284) {name = "358_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 1.009890e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x13x13xsi8>
    %286 = "tpu.load_weight"(%0) {name = "359_Exp_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %287 = "tpu.load_weight"(%0) {name = "359_Exp_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %288 = "tpu.exp"(%262, %286, %287) {name = "359_Exp", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 5.330470e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x6x13x13xsi8>
    %289 = "tpu.load_weight"(%0) {name = "360_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %290 = "tpu.load_weight"(%0) {name = "360_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %291 = "tpu.sigmoid"(%267, %289, %290) {name = "360_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 1.875800e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x507xsi8>
    %292 = "tpu.load_weight"(%0) {name = "361_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %293 = "tpu.load_weight"(%0) {name = "361_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %294 = "tpu.sigmoid"(%276, %292, %293) {name = "361_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 6.253000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x80xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x507x80xsi8>
    %295 = "tpu.crop"(%285) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "366_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.009890e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %296 = "tpu.load_weight"(%0) {name = "368_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %297 = "tpu.none"() : () -> none
    %298 = "tpu.load_weight"(%0) {name = "368_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %299 = "tpu.load_weight"(%0) {name = "368_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %300 = "tpu.eltwise_add"(%295, %296, %297, %297, %298, %299) {do_relu = false, name = "368_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.6735401 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %301 = "tpu.crop"(%285) {crop_offset = [0 : i32, 1 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "373_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 0.991299986 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %302 = "tpu.load_weight"(%0) {name = "375_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %303 = "tpu.none"() : () -> none
    %304 = "tpu.load_weight"(%0) {name = "375_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %305 = "tpu.load_weight"(%0) {name = "375_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %306 = "tpu.eltwise_add"(%301, %302, %303, %303, %304, %305) {do_relu = false, name = "375_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.91222 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %307 = "tpu.crop"(%288) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "380_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 5.330470e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %308 = "tpu.load_weight"(%0) {name = "380_mul_weight_scale_13.492760_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %309 = "tpu.load_weight"(%0) {name = "380_mul_bias_scale_13.492760_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %310 = "tpu.none"() : () -> none
    %311 = "tpu.load_weight"(%0) {name = "382_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %312 = "tpu.load_weight"(%0) {name = "382_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %313 = "tpu.conv_2d"(%307, %308, %309, %310, %310, %311, %312) {name = "382_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 13.4927597 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %314 = "tpu.crop"(%288) {crop_offset = [0 : i32, 1 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "387_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.782770e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %315 = "tpu.load_weight"(%0) {name = "387_mul_weight_scale_7.130860_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %316 = "tpu.load_weight"(%0) {name = "387_mul_bias_scale_7.130860_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %317 = "tpu.none"() : () -> none
    %318 = "tpu.load_weight"(%0) {name = "389_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %319 = "tpu.load_weight"(%0) {name = "389_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %320 = "tpu.conv_2d"(%314, %315, %316, %317, %317, %318, %319) {name = "389_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 7.130860e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %321 = "tpu.crop"(%285) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "394_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.017050e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %322 = "tpu.load_weight"(%0) {name = "396_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %323 = "tpu.none"() : () -> none
    %324 = "tpu.load_weight"(%0) {name = "396_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %325 = "tpu.load_weight"(%0) {name = "396_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %326 = "tpu.eltwise_add"(%321, %322, %323, %323, %324, %325) {do_relu = false, name = "396_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.5712605 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %327 = "tpu.crop"(%285) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "401_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 9.862800e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %328 = "tpu.load_weight"(%0) {name = "403_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %329 = "tpu.none"() : () -> none
    %330 = "tpu.load_weight"(%0) {name = "403_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %331 = "tpu.load_weight"(%0) {name = "403_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %332 = "tpu.eltwise_add"(%327, %328, %329, %329, %330, %331) {do_relu = false, name = "403_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.70506 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %333 = "tpu.crop"(%288) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "408_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 6.296480e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %334 = "tpu.load_weight"(%0) {name = "408_mul_weight_scale_26.563259_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %335 = "tpu.load_weight"(%0) {name = "408_mul_bias_scale_26.563259_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %336 = "tpu.none"() : () -> none
    %337 = "tpu.load_weight"(%0) {name = "410_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %338 = "tpu.load_weight"(%0) {name = "410_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %339 = "tpu.conv_2d"(%333, %334, %335, %336, %336, %337, %338) {name = "410_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 26.5632591 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %340 = "tpu.crop"(%288) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "415_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.551680e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %341 = "tpu.load_weight"(%0) {name = "415_mul_weight_scale_13.476050_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %342 = "tpu.load_weight"(%0) {name = "415_mul_bias_scale_13.476050_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %343 = "tpu.none"() : () -> none
    %344 = "tpu.load_weight"(%0) {name = "417_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %345 = "tpu.load_weight"(%0) {name = "417_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %346 = "tpu.conv_2d"(%340, %341, %342, %343, %343, %344, %345) {name = "417_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 13.4760504 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %347 = "tpu.crop"(%285) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "422_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 9.977800e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %348 = "tpu.load_weight"(%0) {name = "424_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %349 = "tpu.none"() : () -> none
    %350 = "tpu.load_weight"(%0) {name = "424_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %351 = "tpu.load_weight"(%0) {name = "424_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %352 = "tpu.eltwise_add"(%347, %348, %349, %349, %350, %351) {do_relu = false, name = "424_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.7427397 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %353 = "tpu.crop"(%285) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "429_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.003480e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %354 = "tpu.load_weight"(%0) {name = "431_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x13x13xf32>
    %355 = "tpu.none"() : () -> none
    %356 = "tpu.load_weight"(%0) {name = "431_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %357 = "tpu.load_weight"(%0) {name = "431_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %358 = "tpu.eltwise_add"(%353, %354, %355, %355, %356, %357) {do_relu = false, name = "431_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.4293098 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x13x13xsi8>
    %359 = "tpu.crop"(%288) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "436_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.934660e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %360 = "tpu.load_weight"(%0) {name = "436_mul_weight_scale_31.547550_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %361 = "tpu.load_weight"(%0) {name = "436_mul_bias_scale_31.547550_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %362 = "tpu.none"() : () -> none
    %363 = "tpu.load_weight"(%0) {name = "438_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %364 = "tpu.load_weight"(%0) {name = "438_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %365 = "tpu.conv_2d"(%359, %360, %361, %362, %362, %363, %364) {name = "438_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 31.5475502 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %366 = "tpu.crop"(%288) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 13 : i32, 13 : i32], name = "443_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.454330e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x1x13x13xsi8>
    %367 = "tpu.load_weight"(%0) {name = "443_mul_weight_scale_14.497880_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %368 = "tpu.load_weight"(%0) {name = "443_mul_bias_scale_14.497880_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %369 = "tpu.none"() : () -> none
    %370 = "tpu.load_weight"(%0) {name = "445_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %371 = "tpu.load_weight"(%0) {name = "445_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %372 = "tpu.conv_2d"(%366, %367, %368, %369, %369, %370, %371) {name = "445_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 14.49788 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x13x13xsi8>
    %373 = "tpu.none"() : () -> none
    %374 = "tpu.load_weight"(%0) {name = "446_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %375 = "tpu.load_weight"(%0) {name = "446_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %376 = "tpu.concat"(%300, %326, %352, %373, %373, %374, %375) {axis = 1 : i32, name = "446_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.7427397 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x13x13xsi8>
    %377 = "tpu.none"() : () -> none
    %378 = "tpu.load_weight"(%0) {name = "447_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %379 = "tpu.load_weight"(%0) {name = "447_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %380 = "tpu.concat"(%306, %332, %358, %377, %377, %378, %379) {axis = 1 : i32, name = "447_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.91222 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x13x13xsi8>
    %381 = "tpu.none"() : () -> none
    %382 = "tpu.load_weight"(%0) {name = "448_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %383 = "tpu.load_weight"(%0) {name = "448_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %384 = "tpu.concat"(%313, %339, %365, %381, %381, %382, %383) {axis = 1 : i32, name = "448_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 26.5632591 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x13x13xsi8>
    %385 = "tpu.none"() : () -> none
    %386 = "tpu.load_weight"(%0) {name = "449_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %387 = "tpu.load_weight"(%0) {name = "449_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %388 = "tpu.concat"(%320, %346, %372, %385, %385, %386, %387) {axis = 1 : i32, name = "449_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 14.49788 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, tensor<1x1x13x13xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x13x13xsi8>
    %389 = "tpu.none"() : () -> none
    %390 = "tpu.load_weight"(%0) {name = "450_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %391 = "tpu.load_weight"(%0) {name = "450_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %392 = "tpu.concat"(%376, %384, %389, %389, %390, %391) {axis = 1 : i32, name = "450_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 19.3187408 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x13x13xsi8>, tensor<1x3x13x13xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x6x13x13xsi8>
    %393 = "tpu.none"() : () -> none
    %394 = "tpu.load_weight"(%0) {name = "451_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %395 = "tpu.load_weight"(%0) {name = "451_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %396 = "tpu.concat"(%380, %388, %393, %393, %394, %395) {axis = 1 : i32, name = "451_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 12.6856499 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x13x13xsi8>, tensor<1x3x13x13xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x6x13x13xsi8>
    %397 = "tpu.load_weight"(%0) {name = "450_div_weight_scale_0.980210_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %398 = "tpu.load_weight"(%0) {name = "450_div_bias_scale_0.980210_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %399 = "tpu.none"() : () -> none
    %400 = "tpu.load_weight"(%0) {name = "456_Div_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %401 = "tpu.load_weight"(%0) {name = "456_Div_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %402 = "tpu.conv_2d"(%392, %397, %398, %399, %399, %400, %401) {name = "456_Div", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 9.802100e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x13x13xsi8>
    %403 = "tpu.load_weight"(%0) {name = "451_div_weight_scale_0.993250_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %404 = "tpu.load_weight"(%0) {name = "451_div_bias_scale_0.993250_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %405 = "tpu.none"() : () -> none
    %406 = "tpu.load_weight"(%0) {name = "461_Div_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %407 = "tpu.load_weight"(%0) {name = "461_Div_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %408 = "tpu.conv_2d"(%396, %403, %404, %405, %405, %406, %407) {name = "461_Div", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 9.932500e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x13x13xsi8>
    %409 = "tpu.crop"(%402) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 13 : i32, 13 : i32], name = "466_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 9.802100e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x3x13x13xsi8>
    %410 = "tpu.reshape"(%409) {name = "484_Reshape"} : (tensor<1x3x13x13xsi8>) -> tensor<1x507x1xsi8>
    %411 = "tpu.crop"(%408) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 13 : i32, 13 : i32], name = "489_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 9.932500e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x3x13x13xsi8>
    %412 = "tpu.reshape"(%411) {name = "507_Reshape"} : (tensor<1x3x13x13xsi8>) -> tensor<1x507x1xsi8>
    %413 = "tpu.crop"(%402) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 13 : i32, 13 : i32], name = "512_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.043330e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x3x13x13xsi8>
    %414 = "tpu.reshape"(%413) {name = "530_Reshape"} : (tensor<1x3x13x13xsi8>) -> tensor<1x507x1xsi8>
    %415 = "tpu.crop"(%408) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 13 : i32, 13 : i32], name = "535_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.115220e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x13x13xsi8>) -> tensor<1x3x13x13xsi8>
    %416 = "tpu.reshape"(%415) {name = "553_Reshape"} : (tensor<1x3x13x13xsi8>) -> tensor<1x507x1xsi8>
    %417 = "tpu.load_weight"(%0) {name = "556_scale_Sub_fold_0_scale_1.021660_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<507x1x1x1x1xf32>
    %418 = "tpu.load_weight"(%0) {name = "556_scale_Sub_fold_1_scale_1.021660_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<507xf32>
    %419 = "tpu.none"() : () -> none
    %420 = "tpu.load_weight"(%0) {name = "556_scale_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<507xf32>
    %421 = "tpu.load_weight"(%0) {name = "556_scale_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<507xf32>
    %422 = "tpu.conv_2d"(%414, %417, %418, %419, %419, %420, %421) {name = "556_scale_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 507 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 1.021660e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<507x1x1x1x1xf32>, tensor<507xf32>, none, none, tensor<507xf32>, tensor<507xf32>) -> tensor<1x507x1xsi8>
    %423 = "tpu.none"() : () -> none
    %424 = "tpu.load_weight"(%0) {name = "556_Sub_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %425 = "tpu.load_weight"(%0) {name = "556_Sub_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %426 = "tpu.eltwise_add"(%410, %422, %423, %423, %424, %425) {do_relu = false, name = "556_Sub", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.049160e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x507x1xsi8>
    %427 = "tpu.load_weight"(%0) {name = "559_scale_Sub_fold_0_scale_0.557610_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<507x1x1x1x1xf32>
    %428 = "tpu.load_weight"(%0) {name = "559_scale_Sub_fold_1_scale_0.557610_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<507xf32>
    %429 = "tpu.none"() : () -> none
    %430 = "tpu.load_weight"(%0) {name = "559_scale_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<507xf32>
    %431 = "tpu.load_weight"(%0) {name = "559_scale_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<507xf32>
    %432 = "tpu.conv_2d"(%416, %427, %428, %429, %429, %430, %431) {name = "559_scale_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 507 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 5.576100e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<507x1x1x1x1xf32>, tensor<507xf32>, none, none, tensor<507xf32>, tensor<507xf32>) -> tensor<1x507x1xsi8>
    %433 = "tpu.none"() : () -> none
    %434 = "tpu.load_weight"(%0) {name = "559_Sub_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %435 = "tpu.load_weight"(%0) {name = "559_Sub_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %436 = "tpu.eltwise_add"(%412, %432, %433, %433, %434, %435) {do_relu = false, name = "559_Sub", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 0.957979977 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x507x1xsi8>
    %437 = "tpu.none"() : () -> none
    %438 = "tpu.load_weight"(%0) {name = "560_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %439 = "tpu.load_weight"(%0) {name = "560_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %440 = "tpu.eltwise_add"(%426, %414, %437, %437, %438, %439) {do_relu = false, name = "560_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.553580e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x507x1xsi8>
    %441 = "tpu.none"() : () -> none
    %442 = "tpu.load_weight"(%0) {name = "561_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %443 = "tpu.load_weight"(%0) {name = "561_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %444 = "tpu.eltwise_add"(%436, %416, %441, %441, %442, %443) {do_relu = false, name = "561_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.273770e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x507x1xsi8>
    %445 = "tpu.none"() : () -> none
    %446 = "tpu.load_weight"(%0) {name = "562_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %447 = "tpu.load_weight"(%0) {name = "562_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<4xf32>
    %448 = "tpu.concat"(%426, %436, %440, %444, %445, %445, %446, %447) {axis = 2 : i32, name = "562_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.553580e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<4xf32>) -> tensor<1x507x4xsi8>
    %449 = "tpu.reshape"(%448) {name = "582_Reshape"} : (tensor<1x507x4xsi8>) -> tensor<1x507x1x4xsi8>
    %450 = "tpu.reshape"(%291) {name = "600_Reshape"} : (tensor<1x507xsi8>) -> tensor<1x507x1xsi8>
    %451 = "tpu.none"() : () -> none
    %452 = "tpu.load_weight"(%0) {name = "601_Mul_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %453 = "tpu.load_weight"(%0) {name = "601_Mul_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %454 = "tpu.broadcast_mul"(%294, %450, %451, %451, %452, %453) {axis = 1 : i32, name = "601_Mul", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 6.251000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x80xsi8>, tensor<1x507x1xsi8>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x507x80x1xsi8>
    %455 = "tpu.none"() : () -> none
    %456 = "tpu.load_weight"(%0) {name = "603_BatchNormalization_merge_scale_0_18.583630_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<128x256x1x1xf32>
    %457 = "tpu.load_weight"(%0) {name = "603_BatchNormalization_merge_scale_1_18.583630_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<128xf32>
    %458 = "tpu.load_weight"(%0) {name = "603_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %459 = "tpu.load_weight"(%0) {name = "603_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<128xf32>
    %460 = "tpu.conv_2d"(%224, %456, %457, %455, %455, %458, %459) {name = "603_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 18.5836296 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x13x13xsi8>, tensor<128x256x1x1xf32>, tensor<128xf32>, none, none, tensor<128xf32>, tensor<128xf32>) -> tensor<1x128x13x13xsi8>
    %461 = "tpu.none"() : () -> none
    %462 = "tpu.load_weight"(%0) {name = "604_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %463 = "tpu.load_weight"(%0) {name = "604_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %464 = "tpu.load_weight"(%0) {name = "604_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %465 = "tpu.load_weight"(%0) {name = "604_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %466 = "tpu.leaky_relu"(%460, %461, %461, %461, %461, %462, %463, %464, %465) {name = "604_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 18.5836296 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x13x13xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x128x13x13xsi8>
    %467 = "tpu.reshape"(%466) {name = "656_reshape"} : (tensor<1x128x13x13xsi8>) -> tensor<1664x1x13x1xsi8>
    %468 = "tpu.load_weight"(%0) {name = "656_Expand_w_filter_18.583630_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x2xf32>
    %469 = "tpu.none"() : () -> none
    %470 = "tpu.load_weight"(%0) {name = "656_Expand_w_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %471 = "tpu.load_weight"(%0) {name = "656_Expand_w_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %472 = "tpu.deconv_2d"(%467, %468, %469, %469, %469, %470, %471) {name = "656_Expand_w", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 2 : i32, with_bias = false}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 18.5836296 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1664x1x13x1xsi8>, tensor<1x1x1x2xf32>, none, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1664x1x13x2xsi8>
    %473 = "tpu.reshape"(%472) {name = "656_reshape_w"} : (tensor<1664x1x13x2xsi8>) -> tensor<1664x1x1x26xsi8>
    %474 = "tpu.load_weight"(%0) {name = "656_Expand_filter_18.583630_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x2x1xf32>
    %475 = "tpu.none"() : () -> none
    %476 = "tpu.load_weight"(%0) {name = "656_Expand_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %477 = "tpu.load_weight"(%0) {name = "656_Expand_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %478 = "tpu.deconv_2d"(%473, %474, %475, %475, %475, %476, %477) {name = "656_Expand", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 2 : i32, stride_w = 1 : i32, with_bias = false}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 18.5836296 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1664x1x1x26xsi8>, tensor<1x1x2x1xf32>, none, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1664x1x2x26xsi8>
    %479 = "tpu.reshape"(%478) {name = "678_Reshape"} : (tensor<1664x1x2x26xsi8>) -> tensor<1x128x26x26xsi8>
    %480 = "tpu.none"() : () -> none
    %481 = "tpu.load_weight"(%0) {name = "679_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %482 = "tpu.load_weight"(%0) {name = "679_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %483 = "tpu.concat"(%479, %195, %480, %480, %481, %482) {axis = 1 : i32, name = "679_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 14.3327799 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x128x26x26xsi8>, tensor<1x256x26x26xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x384x26x26xsi8>
    %484 = "tpu.none"() : () -> none
    %485 = "tpu.load_weight"(%0) {name = "681_BatchNormalization_merge_scale_0_9.979500_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<256x384x3x3xf32>
    %486 = "tpu.load_weight"(%0) {name = "681_BatchNormalization_merge_scale_1_9.979500_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<256xf32>
    %487 = "tpu.load_weight"(%0) {name = "681_BatchNormalization_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %488 = "tpu.load_weight"(%0) {name = "681_BatchNormalization_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<256xf32>
    %489 = "tpu.conv_2d"(%483, %485, %486, %484, %484, %487, %488) {name = "681_BatchNormalization", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "SAME", padding_b = 1 : i32, padding_l = 1 : i32, padding_r = 1 : i32, padding_t = 1 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 9.97949981 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x384x26x26xsi8>, tensor<256x384x3x3xf32>, tensor<256xf32>, none, none, tensor<256xf32>, tensor<256xf32>) -> tensor<1x256x26x26xsi8>
    %490 = "tpu.none"() : () -> none
    %491 = "tpu.load_weight"(%0) {name = "682_LeakyRelu_rshift_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %492 = "tpu.load_weight"(%0) {name = "682_LeakyRelu_multiplier_pos", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %493 = "tpu.load_weight"(%0) {name = "682_LeakyRelu_rshift_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %494 = "tpu.load_weight"(%0) {name = "682_LeakyRelu_multiplier_neg", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %495 = "tpu.leaky_relu"(%489, %490, %490, %490, %490, %491, %492, %493, %494) {name = "682_LeakyRelu", negative_slope = 1.000000e-01 : f32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 9.97949981 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, none, none, none, none, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>, tensor<1xf32>) -> tensor<1x256x26x26xsi8>
    %496 = "tpu.load_weight"(%0) {name = "models.36.conv21.weight_4.809650_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<255x256x1x1xf32>
    %497 = "tpu.load_weight"(%0) {name = "models.36.conv21.bias_4.809650_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<255xf32>
    %498 = "tpu.none"() : () -> none
    %499 = "tpu.load_weight"(%0) {name = "683_Conv_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<255xf32>
    %500 = "tpu.load_weight"(%0) {name = "683_Conv_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<255xf32>
    %501 = "tpu.conv_2d"(%495, %496, %497, %498, %498, %499, %500) {name = "683_Conv", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = false, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 4.809650e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x256x26x26xsi8>, tensor<255x256x1x1xf32>, tensor<255xf32>, none, none, tensor<255xf32>, tensor<255xf32>) -> tensor<1x255x26x26xsi8>
    %502 = "tpu.crop"(%501) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "688_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 4.809650e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %503 = "tpu.crop"(%501) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "693_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.330330e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %504 = "tpu.crop"(%501) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "698_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 26.8914108 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %505 = "tpu.crop"(%501) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 26 : i32, 26 : i32], name = "703_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 34.1588593 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x80x26x26xsi8>
    %506 = "tpu.crop"(%501) {crop_offset = [0 : i32, 85 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "708_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 3.800070e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %507 = "tpu.crop"(%501) {crop_offset = [0 : i32, 87 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "713_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.093510e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %508 = "tpu.crop"(%501) {crop_offset = [0 : i32, 89 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "718_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 28.255619 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %509 = "tpu.crop"(%501) {crop_offset = [0 : i32, 90 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 26 : i32, 26 : i32], name = "723_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 32.1786118 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x80x26x26xsi8>
    %510 = "tpu.crop"(%501) {crop_offset = [0 : i32, 170 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "728_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 4.150290e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %511 = "tpu.crop"(%501) {crop_offset = [0 : i32, 172 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 2 : i32, 26 : i32, 26 : i32], name = "733_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.130070e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x2x26x26xsi8>
    %512 = "tpu.crop"(%501) {crop_offset = [0 : i32, 174 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "738_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 25.9595299 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %513 = "tpu.crop"(%501) {crop_offset = [0 : i32, 175 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 80 : i32, 26 : i32, 26 : i32], name = "743_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 30.3043404 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x255x26x26xsi8>) -> tensor<1x80x26x26xsi8>
    %514 = "tpu.none"() : () -> none
    %515 = "tpu.load_weight"(%0) {name = "744_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %516 = "tpu.load_weight"(%0) {name = "744_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %517 = "tpu.concat"(%502, %506, %510, %514, %514, %515, %516) {axis = 1 : i32, name = "744_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 4.809650e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2x26x26xsi8>, tensor<1x2x26x26xsi8>, tensor<1x2x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x6x26x26xsi8>
    %518 = "tpu.none"() : () -> none
    %519 = "tpu.load_weight"(%0) {name = "745_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %520 = "tpu.load_weight"(%0) {name = "745_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %521 = "tpu.concat"(%503, %507, %511, %518, %518, %519, %520) {axis = 1 : i32, name = "745_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 2.330330e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2x26x26xsi8>, tensor<1x2x26x26xsi8>, tensor<1x2x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x6x26x26xsi8>
    %522 = "tpu.none"() : () -> none
    %523 = "tpu.load_weight"(%0) {name = "746_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %524 = "tpu.load_weight"(%0) {name = "746_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %525 = "tpu.concat"(%504, %508, %512, %522, %522, %523, %524) {axis = 1 : i32, name = "746_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 26.8914108 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x26x26xsi8>
    %526 = "tpu.reshape"(%525) {name = "762_Reshape"} : (tensor<1x3x26x26xsi8>) -> tensor<1x2028xsi8>
    %527 = "tpu.none"() : () -> none
    %528 = "tpu.load_weight"(%0) {name = "763_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %529 = "tpu.load_weight"(%0) {name = "763_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %530 = "tpu.concat"(%505, %509, %513, %527, %527, %528, %529) {axis = 1 : i32, name = "763_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 31.7189407 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x80x26x26xsi8>, tensor<1x80x26x26xsi8>, tensor<1x80x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x240x26x26xsi8>
    %531 = "tpu.reshape"(%530) {name = "781_Reshape"} : (tensor<1x240x26x26xsi8>) -> tensor<1x3x80x676xsi8>
    %532 = "tpu.reshape"(%531) {name = "782_Transpose_for_0231"} : (tensor<1x3x80x676xsi8>) -> tensor<3x80x1x676xsi8>
    %533 = "tpu.permute"(%532) {name = "782_Transpose", order0 = 0 : i32, order1 = 2 : i32, order2 = 3 : i32, order3 = 1 : i32, quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 31.7189407 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<3x80x1x676xsi8>) -> tensor<3x1x676x80xsi8>
    %534 = "tpu.reshape"(%533) {name = "782_Transpose_back_for_0231"} : (tensor<3x1x676x80xsi8>) -> tensor<1x3x676x80xsi8>
    %535 = "tpu.reshape"(%534) {name = "800_Reshape"} : (tensor<1x3x676x80xsi8>) -> tensor<1x2028x80xsi8>
    %536 = "tpu.load_weight"(%0) {name = "801_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %537 = "tpu.load_weight"(%0) {name = "801_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %538 = "tpu.sigmoid"(%517, %536, %537) {name = "801_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 9.923800e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x6x26x26xsi8>
    %539 = "tpu.load_weight"(%0) {name = "805_Sub_fold_0_scale_1.015600_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %540 = "tpu.load_weight"(%0) {name = "805_Sub_fold_1_scale_1.015600_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %541 = "tpu.none"() : () -> none
    %542 = "tpu.load_weight"(%0) {name = "805_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %543 = "tpu.load_weight"(%0) {name = "805_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %544 = "tpu.conv_2d"(%538, %539, %540, %541, %541, %542, %543) {name = "805_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 1.015600e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x26x26xsi8>
    %545 = "tpu.load_weight"(%0) {name = "806_Exp_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %546 = "tpu.load_weight"(%0) {name = "806_Exp_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %547 = "tpu.exp"(%521, %545, %546) {name = "806_Exp", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 6.140360e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x6x26x26xsi8>
    %548 = "tpu.load_weight"(%0) {name = "807_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %549 = "tpu.load_weight"(%0) {name = "807_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %550 = "tpu.sigmoid"(%526, %548, %549) {name = "807_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 5.897000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x2028xsi8>
    %551 = "tpu.load_weight"(%0) {name = "808_Sigmoid_y0_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %552 = "tpu.load_weight"(%0) {name = "808_Sigmoid_mantissa_table", storage = "INT8"} : (memref<10xf32>) -> tensor<1x32x16x16xf32>
    %553 = "tpu.sigmoid"(%535, %551, %552) {name = "808_Sigmoid", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "LUT_INT8", threshold_max = 6.253000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x80xsi8>, tensor<1x32x16x16xf32>, tensor<1x32x16x16xf32>) -> tensor<1x2028x80xsi8>
    %554 = "tpu.crop"(%544) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "813_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.015600e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %555 = "tpu.load_weight"(%0) {name = "815_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %556 = "tpu.none"() : () -> none
    %557 = "tpu.load_weight"(%0) {name = "815_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %558 = "tpu.load_weight"(%0) {name = "815_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %559 = "tpu.eltwise_add"(%554, %555, %556, %556, %557, %558) {do_relu = false, name = "815_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.9727192 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %560 = "tpu.crop"(%544) {crop_offset = [0 : i32, 1 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "820_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.016990e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %561 = "tpu.load_weight"(%0) {name = "822_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %562 = "tpu.none"() : () -> none
    %563 = "tpu.load_weight"(%0) {name = "822_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %564 = "tpu.load_weight"(%0) {name = "822_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %565 = "tpu.eltwise_add"(%560, %561, %562, %562, %563, %564) {do_relu = false, name = "822_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.9013901 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %566 = "tpu.crop"(%547) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "827_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 6.140360e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %567 = "tpu.load_weight"(%0) {name = "827_mul_weight_scale_8.826770_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %568 = "tpu.load_weight"(%0) {name = "827_mul_bias_scale_8.826770_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %569 = "tpu.none"() : () -> none
    %570 = "tpu.load_weight"(%0) {name = "829_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %571 = "tpu.load_weight"(%0) {name = "829_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %572 = "tpu.conv_2d"(%566, %567, %568, %569, %569, %570, %571) {name = "829_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 8.82676982 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %573 = "tpu.crop"(%547) {crop_offset = [0 : i32, 1 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "834_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 3.767070e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %574 = "tpu.load_weight"(%0) {name = "834_mul_weight_scale_6.356920_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %575 = "tpu.load_weight"(%0) {name = "834_mul_bias_scale_6.356920_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %576 = "tpu.none"() : () -> none
    %577 = "tpu.load_weight"(%0) {name = "836_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %578 = "tpu.load_weight"(%0) {name = "836_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %579 = "tpu.conv_2d"(%573, %574, %575, %576, %576, %577, %578) {name = "836_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 6.356920e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %580 = "tpu.crop"(%544) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "841_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.004330e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %581 = "tpu.load_weight"(%0) {name = "843_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %582 = "tpu.none"() : () -> none
    %583 = "tpu.load_weight"(%0) {name = "843_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %584 = "tpu.load_weight"(%0) {name = "843_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %585 = "tpu.eltwise_add"(%580, %581, %582, %582, %583, %584) {do_relu = false, name = "843_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.8880291 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %586 = "tpu.crop"(%544) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "848_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.011990e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %587 = "tpu.load_weight"(%0) {name = "850_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %588 = "tpu.none"() : () -> none
    %589 = "tpu.load_weight"(%0) {name = "850_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %590 = "tpu.load_weight"(%0) {name = "850_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %591 = "tpu.eltwise_add"(%586, %587, %588, %588, %589, %590) {do_relu = false, name = "850_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.6067791 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %592 = "tpu.crop"(%547) {crop_offset = [0 : i32, 2 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "855_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 2.725600e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %593 = "tpu.load_weight"(%0) {name = "855_mul_weight_scale_6.302940_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %594 = "tpu.load_weight"(%0) {name = "855_mul_bias_scale_6.302940_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %595 = "tpu.none"() : () -> none
    %596 = "tpu.load_weight"(%0) {name = "857_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %597 = "tpu.load_weight"(%0) {name = "857_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %598 = "tpu.conv_2d"(%592, %593, %594, %595, %595, %596, %597) {name = "857_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 6.302940e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %599 = "tpu.crop"(%547) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "862_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 5.477440e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %600 = "tpu.load_weight"(%0) {name = "862_mul_weight_scale_19.855721_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %601 = "tpu.load_weight"(%0) {name = "862_mul_bias_scale_19.855721_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %602 = "tpu.none"() : () -> none
    %603 = "tpu.load_weight"(%0) {name = "864_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %604 = "tpu.load_weight"(%0) {name = "864_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %605 = "tpu.conv_2d"(%599, %600, %601, %602, %602, %603, %604) {name = "864_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 19.8557205 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %606 = "tpu.crop"(%544) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "869_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.009170e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %607 = "tpu.load_weight"(%0) {name = "871_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %608 = "tpu.none"() : () -> none
    %609 = "tpu.load_weight"(%0) {name = "871_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %610 = "tpu.load_weight"(%0) {name = "871_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %611 = "tpu.eltwise_add"(%606, %607, %608, %608, %609, %610) {do_relu = false, name = "871_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.7657108 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %612 = "tpu.crop"(%544) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "876_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 1.004650e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %613 = "tpu.load_weight"(%0) {name = "878_add_bias_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x26x26xf32>
    %614 = "tpu.none"() : () -> none
    %615 = "tpu.load_weight"(%0) {name = "878_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %616 = "tpu.load_weight"(%0) {name = "878_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %617 = "tpu.eltwise_add"(%612, %613, %614, %614, %615, %616) {do_relu = false, name = "878_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.7661209 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xf32>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x1x26x26xsi8>
    %618 = "tpu.crop"(%547) {crop_offset = [0 : i32, 4 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "883_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 5.984770e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %619 = "tpu.load_weight"(%0) {name = "883_mul_weight_scale_30.297920_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %620 = "tpu.load_weight"(%0) {name = "883_mul_bias_scale_30.297920_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %621 = "tpu.none"() : () -> none
    %622 = "tpu.load_weight"(%0) {name = "885_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %623 = "tpu.load_weight"(%0) {name = "885_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %624 = "tpu.conv_2d"(%618, %619, %620, %621, %621, %622, %623) {name = "885_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 30.2979202 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %625 = "tpu.crop"(%547) {crop_offset = [0 : i32, 5 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 1 : i32, 26 : i32, 26 : i32], name = "890_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 3.408430e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x1x26x26xsi8>
    %626 = "tpu.load_weight"(%0) {name = "890_mul_weight_scale_17.468201_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<1x1x1x1x1xf32>
    %627 = "tpu.load_weight"(%0) {name = "890_mul_bias_scale_17.468201_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<1xf32>
    %628 = "tpu.none"() : () -> none
    %629 = "tpu.load_weight"(%0) {name = "892_Mul_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %630 = "tpu.load_weight"(%0) {name = "892_Mul_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<1xf32>
    %631 = "tpu.conv_2d"(%625, %626, %627, %628, %628, %629, %630) {name = "892_Mul", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 1 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 1.746820e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x1x1x1xf32>, tensor<1xf32>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x1x26x26xsi8>
    %632 = "tpu.none"() : () -> none
    %633 = "tpu.load_weight"(%0) {name = "893_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %634 = "tpu.load_weight"(%0) {name = "893_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %635 = "tpu.concat"(%559, %585, %611, %632, %632, %633, %634) {axis = 1 : i32, name = "893_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.9727192 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x26x26xsi8>
    %636 = "tpu.none"() : () -> none
    %637 = "tpu.load_weight"(%0) {name = "894_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %638 = "tpu.load_weight"(%0) {name = "894_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %639 = "tpu.concat"(%565, %591, %617, %636, %636, %637, %638) {axis = 1 : i32, name = "894_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.9013901 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x26x26xsi8>
    %640 = "tpu.none"() : () -> none
    %641 = "tpu.load_weight"(%0) {name = "895_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %642 = "tpu.load_weight"(%0) {name = "895_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %643 = "tpu.concat"(%572, %598, %624, %640, %640, %641, %642) {axis = 1 : i32, name = "895_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.893620e+01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x26x26xsi8>
    %644 = "tpu.none"() : () -> none
    %645 = "tpu.load_weight"(%0) {name = "896_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %646 = "tpu.load_weight"(%0) {name = "896_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<3xf32>
    %647 = "tpu.concat"(%579, %605, %631, %644, %644, %645, %646) {axis = 1 : i32, name = "896_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 19.8557205 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, tensor<1x1x26x26xsi8>, none, none, tensor<1xf32>, tensor<3xf32>) -> tensor<1x3x26x26xsi8>
    %648 = "tpu.none"() : () -> none
    %649 = "tpu.load_weight"(%0) {name = "897_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %650 = "tpu.load_weight"(%0) {name = "897_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %651 = "tpu.concat"(%635, %643, %648, %648, %649, %650) {axis = 1 : i32, name = "897_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 26.5106792 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x26x26xsi8>, tensor<1x3x26x26xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x6x26x26xsi8>
    %652 = "tpu.none"() : () -> none
    %653 = "tpu.load_weight"(%0) {name = "898_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %654 = "tpu.load_weight"(%0) {name = "898_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %655 = "tpu.concat"(%639, %647, %652, %652, %653, %654) {axis = 1 : i32, name = "898_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 25.9013901 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x3x26x26xsi8>, tensor<1x3x26x26xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x6x26x26xsi8>
    %656 = "tpu.load_weight"(%0) {name = "897_div_weight_scale_0.998950_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %657 = "tpu.load_weight"(%0) {name = "897_div_bias_scale_0.998950_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %658 = "tpu.none"() : () -> none
    %659 = "tpu.load_weight"(%0) {name = "903_Div_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %660 = "tpu.load_weight"(%0) {name = "903_Div_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %661 = "tpu.conv_2d"(%651, %656, %657, %658, %658, %659, %660) {name = "903_Div", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 9.989500e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x26x26xsi8>
    %662 = "tpu.load_weight"(%0) {name = "898_div_weight_scale_0.996210_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<6x1x1x1x1xf32>
    %663 = "tpu.load_weight"(%0) {name = "898_div_bias_scale_0.996210_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<6xf32>
    %664 = "tpu.none"() : () -> none
    %665 = "tpu.load_weight"(%0) {name = "908_Div_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %666 = "tpu.load_weight"(%0) {name = "908_Div_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<6xf32>
    %667 = "tpu.conv_2d"(%655, %662, %663, %664, %664, %665, %666) {name = "908_Div", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 6 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 0.996209979 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>, tensor<6x1x1x1x1xf32>, tensor<6xf32>, none, none, tensor<6xf32>, tensor<6xf32>) -> tensor<1x6x26x26xsi8>
    %668 = "tpu.crop"(%661) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 26 : i32, 26 : i32], name = "913_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 9.989500e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x3x26x26xsi8>
    %669 = "tpu.reshape"(%668) {name = "931_Reshape"} : (tensor<1x3x26x26xsi8>) -> tensor<1x2028x1xsi8>
    %670 = "tpu.crop"(%667) {crop_offset = [0 : i32, 0 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 26 : i32, 26 : i32], name = "936_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 0.996209979 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x3x26x26xsi8>
    %671 = "tpu.reshape"(%670) {name = "954_Reshape"} : (tensor<1x3x26x26xsi8>) -> tensor<1x2028x1xsi8>
    %672 = "tpu.crop"(%661) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 26 : i32, 26 : i32], name = "959_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 7.283200e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x3x26x26xsi8>
    %673 = "tpu.reshape"(%672) {name = "977_Reshape"} : (tensor<1x3x26x26xsi8>) -> tensor<1x2028x1xsi8>
    %674 = "tpu.crop"(%667) {crop_offset = [0 : i32, 3 : i32, 0 : i32, 0 : i32], crop_shape = [1 : i32, 3 : i32, 26 : i32, 26 : i32], name = "982_Slice", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "NONE", threshold_max = 0.763679981 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x6x26x26xsi8>) -> tensor<1x3x26x26xsi8>
    %675 = "tpu.reshape"(%674) {name = "1000_Reshape"} : (tensor<1x3x26x26xsi8>) -> tensor<1x2028x1xsi8>
    %676 = "tpu.load_weight"(%0) {name = "1003_scale_Sub_fold_0_scale_0.364160_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<2028x1x1x1x1xf32>
    %677 = "tpu.load_weight"(%0) {name = "1003_scale_Sub_fold_1_scale_0.364160_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %678 = "tpu.none"() : () -> none
    %679 = "tpu.load_weight"(%0) {name = "1003_scale_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %680 = "tpu.load_weight"(%0) {name = "1003_scale_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %681 = "tpu.conv_2d"(%673, %676, %677, %678, %678, %679, %680) {name = "1003_scale_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 2028 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 3.641600e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<2028x1x1x1x1xf32>, tensor<2028xf32>, none, none, tensor<2028xf32>, tensor<2028xf32>) -> tensor<1x2028x1xsi8>
    %682 = "tpu.none"() : () -> none
    %683 = "tpu.load_weight"(%0) {name = "1003_Sub_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %684 = "tpu.load_weight"(%0) {name = "1003_Sub_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %685 = "tpu.eltwise_add"(%669, %681, %682, %682, %683, %684) {do_relu = false, name = "1003_Sub", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 0.98874998 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2028x1xsi8>
    %686 = "tpu.load_weight"(%0) {name = "1006_scale_Sub_fold_0_scale_0.381840_quant", storage = "INT8"} : (memref<10xf32>) -> tensor<2028x1x1x1x1xf32>
    %687 = "tpu.load_weight"(%0) {name = "1006_scale_Sub_fold_1_scale_0.381840_quant", storage = "INT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %688 = "tpu.none"() : () -> none
    %689 = "tpu.load_weight"(%0) {name = "1006_scale_Sub_rshift", storage = "UINT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %690 = "tpu.load_weight"(%0) {name = "1006_scale_Sub_multiplier", storage = "UINT32"} : (memref<10xf32>) -> tensor<2028xf32>
    %691 = "tpu.conv_2d"(%675, %686, %687, %688, %688, %689, %690) {name = "1006_scale_Sub", param = {dilation_h = 1 : i32, dilation_w = 1 : i32, do_relu = false, group = 2028 : i32, ins = [], is_dw = true, pad_value = 0 : i32, padding = "VALID", padding_b = 0 : i32, padding_l = 0 : i32, padding_r = 0 : i32, padding_t = 0 : i32, stride_h = 1 : i32, stride_w = 1 : i32, with_bias = true}, quant = {is_asymmetric = false, is_perchannel = true, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 3.818400e-01 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<2028x1x1x1x1xf32>, tensor<2028xf32>, none, none, tensor<2028xf32>, tensor<2028xf32>) -> tensor<1x2028x1xsi8>
    %692 = "tpu.none"() : () -> none
    %693 = "tpu.load_weight"(%0) {name = "1006_Sub_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %694 = "tpu.load_weight"(%0) {name = "1006_Sub_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %695 = "tpu.eltwise_add"(%671, %691, %692, %692, %693, %694) {do_relu = false, name = "1006_Sub", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 0.987699985 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2028x1xsi8>
    %696 = "tpu.none"() : () -> none
    %697 = "tpu.load_weight"(%0) {name = "1007_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %698 = "tpu.load_weight"(%0) {name = "1007_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %699 = "tpu.eltwise_add"(%685, %673, %696, %696, %697, %698) {do_relu = false, name = "1007_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.239210e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2028x1xsi8>
    %700 = "tpu.none"() : () -> none
    %701 = "tpu.load_weight"(%0) {name = "1008_Add_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %702 = "tpu.load_weight"(%0) {name = "1008_Add_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %703 = "tpu.eltwise_add"(%695, %675, %700, %700, %701, %702) {do_relu = false, name = "1008_Add", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.159570e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2028x1xsi8>
    %704 = "tpu.none"() : () -> none
    %705 = "tpu.load_weight"(%0) {name = "1009_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %706 = "tpu.load_weight"(%0) {name = "1009_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<4xf32>
    %707 = "tpu.concat"(%685, %695, %699, %703, %704, %704, %705, %706) {axis = 2 : i32, name = "1009_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.161760e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<4xf32>) -> tensor<1x2028x4xsi8>
    %708 = "tpu.reshape"(%707) {name = "1029_Reshape"} : (tensor<1x2028x4xsi8>) -> tensor<1x2028x1x4xsi8>
    %709 = "tpu.reshape"(%550) {name = "1047_Reshape"} : (tensor<1x2028xsi8>) -> tensor<1x2028x1xsi8>
    %710 = "tpu.none"() : () -> none
    %711 = "tpu.load_weight"(%0) {name = "1048_Mul_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %712 = "tpu.load_weight"(%0) {name = "1048_Mul_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %713 = "tpu.broadcast_mul"(%553, %709, %710, %710, %711, %712) {axis = 1 : i32, name = "1048_Mul", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I32", threshold_max = 5.767000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x2028x80xsi8>, tensor<1x2028x1xsi8>, none, none, tensor<1xf32>, tensor<1xf32>) -> tensor<1x2028x80x1xsi8>
    %714 = "tpu.none"() : () -> none
    %715 = "tpu.load_weight"(%0) {name = "boxes_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %716 = "tpu.load_weight"(%0) {name = "boxes_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %717 = "tpu.concat"(%449, %708, %714, %714, %715, %716) {axis = 1 : i32, name = "boxes_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 1.434080e+00 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x1x4xsi8>, tensor<1x2028x1x4xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2535x1x4xsi8>
    %718 = "tpu.none"() : () -> none
    %719 = "tpu.load_weight"(%0) {name = "confs_Concat_rshift", storage = "NONE"} : (memref<10xf32>) -> tensor<1xf32>
    %720 = "tpu.load_weight"(%0) {name = "confs_Concat_multiplier", storage = "NONE"} : (memref<10xf32>) -> tensor<2xf32>
    %721 = "tpu.concat"(%454, %713, %718, %718, %719, %720) {axis = 1 : i32, name = "confs_Concat", quant = {is_asymmetric = false, is_perchannel = false, mode = "INT8", param_type = "RSHIFT_AND_M_I8", threshold_max = 6.251000e-02 : f32, threshold_min = 0.000000e+00 : f32, zero_point = 0 : i32}} : (tensor<1x507x80x1xsi8>, tensor<1x2028x80x1xsi8>, none, none, tensor<1xf32>, tensor<2xf32>) -> tensor<1x2535x80x1xsi8>
    %722 = "tpu.reshape"(%721) {name = "confs_reshaped"} : (tensor<1x2535x80x1xsi8>) -> tensor<1x2535x80xsi8>
    %723 = "tpu.quant"(%717) {from = "INT8", name = "boxes_Concat_dequant", threshold = 1.434080e+00 : f32, to = "NONE", zero_point = 0 : i32} : (tensor<1x2535x1x4xsi8>) -> tensor<1x2535x1x4xf32>
    %724 = "tpu.quant"(%722) {from = "INT8", name = "confs_reshaped_dequant", threshold = 6.251000e-02 : f32, to = "NONE", zero_point = 0 : i32} : (tensor<1x2535x80xsi8>) -> tensor<1x2535x80xf32>
    return %723, %724 : tensor<1x2535x1x4xf32>, tensor<1x2535x80xf32>
  }
}

